{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b52af9f3-56f6-42dc-807e-d2c2200f3753",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Deep Learning Models for Measuring Mask-Wearing Behavior in Public Spaces\"\n",
    "author: \"Mohammed Guiga\"\n",
    "toc: false\n",
    "number-sections: true\n",
    "bibliography: final_report.bib\n",
    "notes-after-punctuation: true\n",
    "link-citations: true\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-line-numbers: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd97f4-6c4e-4b65-9fc9-d4cc1cd21945",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9808376-0374-4936-b2e8-17de0d43c4d8",
   "metadata": {},
   "source": [
    "Advances in deep learning have brought the technology to a point of maturity where many pre-trained models exist for common tasks, such as object detection. As a result, smaller companies and industries who may have previously lacked the resources to invest in a machine learning department now have the ability to leverage this technology for their own benefit. To explore this further, this paper examines how the Department of Forest Resources, which may have traditionally been far away from software engineering and machine learning, could potentially use this technology to improve their operations. With the maturation of deep learning techniques, the department may now be able to leverage pre-existing models for tasks such as object detection and classification, which can have applications for forest conservation and management, as well as aiding public policy decision makers. The paper also explores the potential challenges and benefits of this approach. By leveraging pre-existing models, the Department of Forest Resources could gain a competitive edge while avoiding the significant investment of time and resources required to develop a machine learning department. The goal of this paper is to demonstrate the feasibility and potential benefits of leveraging deep learning models for practical applications in industries that previously lacked the resources to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea809047-9b03-4cf4-8e42-e01c89afa146",
   "metadata": {},
   "source": [
    "# Introduction - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d2e7b-3862-409c-a69b-fe52762cde74",
   "metadata": {},
   "source": [
    "* Background information and context of the research\n",
    "* Background information on the importance of mask-wearing during the COVID-19 pandemic\n",
    "* Research question or hypothesis\n",
    "* Significance of the study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee3e63-b66b-4ad3-9915-f8a73c51a6ce",
   "metadata": {},
   "source": [
    "# Literature Review - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcab1d-14fa-4fb2-9a6e-37f990f3effa",
   "metadata": {},
   "source": [
    "* Summary of previous research on the topic\n",
    "* Gaps in the existing research that the current study addresses\n",
    "* Summary of previous research on measuring mask-wearing behavior\n",
    "* Discussion of the limitations of traditional methods for monitoring compliance\n",
    "* Overview of deep learning models and their potential for object detection and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1b3ccd-c2f6-4c5b-a8c0-ae5c26f9b298",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42e2e9b-7ac8-4e79-b7fb-69aff036327d",
   "metadata": {},
   "source": [
    "## Research Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18234aa4-1cb6-4866-a2d4-7ef980b11d16",
   "metadata": {},
   "source": [
    "The original research goal was to test the efficacy of 2D/3D image-based sensors to quantify COVID compliance behaviors, namely movement behavior and exposure risk, amongst public trail users. This involved quantifying physical distancing and mask wearing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69cbed8-593e-4614-89f8-0af2be3992c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cec0b7-db07-417b-a0c9-b3ee261e315e",
   "metadata": {},
   "source": [
    "A wireless 2D/3D image sensor prototype was deployed along typical public trail areas. Three locations were selected near amenities such as beaches, food/entertainment, and parks. MPRB permits were issued through summer 2021."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ed42ce0-2b0d-4e7b-9d08-4f3d2bf8d464",
   "metadata": {},
   "source": [
    "The location of the data collection sites are shown in @fig-lakes.\n",
    "\n",
    "::: {#fig-lakes layout-ncol=3}\n",
    "\n",
    "![Lake of the Isles](final_report_images/camera/lake_of_the_isles.png){#fig-isles}\n",
    "\n",
    "![Bde Maka Ska](final_report_images/camera/bde_maka_ska.png){#fig-maka}\n",
    "\n",
    "![Lake Harriet](final_report_images/camera/lake_harriet.png){#fig-harriet}\n",
    "\n",
    "Data Collection Locations\n",
    ":::"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d23664cd-b855-4e9a-9083-88c31933f50c",
   "metadata": {},
   "source": [
    "Examples of the data collection sites are shown in @fig-trails.\n",
    "\n",
    "::: {#fig-trails layout-ncol=3}\n",
    "\n",
    "![Lake of the Isles](final_report_images/camera/lake_of_the_isles_img.jpg){#fig-isles}\n",
    "\n",
    "![Bde Maka Ska](final_report_images/camera/bde_maka_ska_img.jpg){#fig-maka}\n",
    "\n",
    "![Lake Harriet](final_report_images/camera/lake_harriet_img.jpg){#fig-harriet}\n",
    "\n",
    "Data Collection Locations Examples\n",
    ":::"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e43b0dc5-fc1f-43f5-9ea5-86900c0fc9c5",
   "metadata": {},
   "source": [
    "Camera location for each of the data collection sites are shown in @fig-cameras.\n",
    "\n",
    "::: {#fig-cameras layout-ncol=3}\n",
    "\n",
    "![Lake of the Isles](final_report_images/camera/lake_of_the_isles_camera.png){#fig-isles}\n",
    "\n",
    "![Bde Maka Ska](final_report_images/camera/bde_maka_ska_camera.png){#fig-maka}\n",
    "\n",
    "![Lake Harriet](final_report_images/camera/lake_harriet_camera.png){#fig-harriet}\n",
    "\n",
    "Data Collection Camera Positions\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea3840-879b-481b-af0d-452bbbf2b657",
   "metadata": {},
   "source": [
    "This data was established as a feasible method of using a low-cost 2D/3D sensor system to capture detailed trail user movement behaviors, and the results were used to derive a metric to express 'exposure risk' using the detected trail user movement tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22906728-ee9d-4b21-a4a3-e60ab35b721f",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2929ca05-af1a-4333-ab8d-2be09e9c6d86",
   "metadata": {},
   "source": [
    "### Object Detection and Classification Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331d81e-05b5-4032-a8c5-19bd71cc97fd",
   "metadata": {},
   "source": [
    "Several models were evaluated for the tasks of face detection and mask classification. The first model tested was developed by a previous student who worked on this project. This model was trained on a new dataset consisting of real-world images collected from image search sites. The goal of this model was to predict mask-wearing behaviour. This model was not fine-tuned on the images collected from the trails, so it essentially acted as a pure off-the-shelf model. This model showed promising results on training and validation, and in this project was tested on a new real-world trail image dataset. The performance of this model on the real-world dataset is discussed in the results (see @sec-results).\n",
    "\n",
    "Additional off-the-shelf models were tested in the interest of evaluating the feasibility of these off-the-shelf models for real-world applications and industries that may not have access to machine learning expertice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56136d1-07ef-4dc6-83ce-0a71ab31ca56",
   "metadata": {},
   "source": [
    "### Metric Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac37eb-a764-45fe-9727-affe42e1b3f6",
   "metadata": {},
   "source": [
    "Standard metrics were used to evaluate the models introduced above. The metrics chosen were sensitivity, specificity, precision, and accuracy. Sensitvity and specificity are not commonly found when it comes to evaluating deep learning models, but are common to the field of biostatistics, which is relevant to this project. Precision and recall were chosen since they are very common metrics used across the fields of computer science and machine learning. All four metrics were assessed across models and sub-groups, but the focal point will be sensitivity and specificity.\n",
    "\n",
    "Sensitivity is defined as the probability of having a true positive given that you tested positive: $P(T=1 | D=1)$, where T is the true result, and D is the test result.\n",
    "\n",
    "Specificity is defined as the probability of having a true negative given that you tested negative: $P(T=0 | D=0)$, where T is the true result, and D is the test result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ebe8e-98db-4997-a92b-0b960c4bb9a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Results {#sec-results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a44d7-17a1-47c4-86a3-f6d2aa10b56a",
   "metadata": {},
   "source": [
    "* Presentation of the findings, including accuracy rates and potential applications\n",
    "* Graphs and tables\n",
    "* Discussion of the challenges and limitations of the approach, such as privacy concerns and data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62988b9b-bb38-4e6b-a64e-36e199c5a8e9",
   "metadata": {},
   "source": [
    "## Helena NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9308f95-7afc-41f0-a673-f9647a323152",
   "metadata": {},
   "source": [
    "The model provided by the research group was evaluated against the metrics defined above. The results can be seen in @tbl-metrics-full-dataset. Plots can be seen in @fig-all-groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437dd813-2bac-4b79-a735-bed9f736fc3c",
   "metadata": {},
   "source": [
    "::: {#fig-metrics_full_dataset layout-ncol=2}\n",
    "\n",
    "|    Metric   |  Score | Lower bound | Upper bound |\n",
    "|:-----------:|:------:|:-----------:|:-----------:|\n",
    "| Sensitivity | 0.7987 | 0.7614      | 0.8403      |\n",
    "| Specificity | 0.4302 | 0.3916      | 0.4675      |\n",
    "| Precision   | 0.5417 | 0.5094      | 0.5856      |\n",
    "| Accuracy    | 0.5988 | 0.5654      | 0.6233      |\n",
    "\n",
    ": Metrics - full dataset {#tbl-metrics-full-dataset}\n",
    "\n",
    "![Metrics with Confidence Intervals](final_report_images/metrics/all_groups_metrics.png){#fig-all-groups}\n",
    "\n",
    "Deep Neural Network Metrics\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d8bfe-fa1b-47a2-9099-aec2431dc34f",
   "metadata": {},
   "source": [
    "### Sub-group Metric Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7546d81a-f2e8-463f-8447-c1fe5afcaf10",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Image Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43caaf5e-0b98-4625-bd7f-99331394369c",
   "metadata": {},
   "source": [
    "Quadrant 1 image examples can be seen in @fig-q1\n",
    "\n",
    "::: {#fig-q1 layout-ncol=2}\n",
    "\n",
    "![](final_report_images/examples/q1/q1_1.png)\n",
    "\n",
    "![](final_report_images/examples/q1/q1_2.png)\n",
    "\n",
    "Quadrant 1 Examples\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef9e52-4446-4b01-a077-689f51028976",
   "metadata": {},
   "source": [
    "Quadrant 3 image examples can be seen in @fig-q3\n",
    "\n",
    "::: {#fig-q3 layout-ncol=2}\n",
    "\n",
    "![](final_report_images/examples/q3/q3_1.png)\n",
    "\n",
    "![](final_report_images/examples/q3/q3_2.png)\n",
    "\n",
    "Quadrant 3 Examples\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7830bf92-0a61-4565-b2a0-9138b22d1ea4",
   "metadata": {},
   "source": [
    "#### Sub-group Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819366d-20bd-44fd-9e72-321501387930",
   "metadata": {},
   "source": [
    "See @fig-quadrants for metrics calculated across frame quadrants. The first and third quadrants represent the upper-left and upper-right quadrants of each frame, respectively. Quadrants 2 and 4 represent the bottom two quadrants of each frame, and in most cases are images of the ground. In this analysis, all faces were found in quadrants 1 and 3. Both quadrant 1 and quadrant 3 have poor specificity, with quadrant 3 having very poor specificity compared to the entire dataset. Both of these quadrants have high sensitivity also, which indicates overprediction independant of quadrant.\n",
    "\n",
    "![Metrics Across Quadrants](final_report_images/metrics/quadrants_metrics.png){#fig-quadrants width=80%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331ba86-0579-4fe1-90ca-6bba16c4344a",
   "metadata": {},
   "source": [
    "See @fig-dates for metrics calculated across dates. In terms of specificity, all dates have poor specificity, and high sensitivity, indicating overprediction independant of date.\n",
    "\n",
    "![Metrics Across Dates](final_report_images/metrics/dates_metrics.png){#fig-dates width=80%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb4357-c9d0-4c49-8a4b-b79172e4b735",
   "metadata": {},
   "source": [
    "See @fig-quadrants-dates for metrics across a combination of quadrants and dates. The hypothesis is that since both the quadrants and dates yielded similar results, the combination will yield overpredicion as well.\n",
    "\n",
    "![Metrics Across Quadrants and Dates](final_report_images/metrics/quadrants_dates_metrics.png){#fig-quadrants-dates width=80%}\n",
    "\n",
    "As can be seen in @fig-quadrants-dates, each sub-group has high sensitivity and low specificity, which aligns with the overprediction hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8fb91-d9d9-409e-bea1-ceedaefc73bb",
   "metadata": {},
   "source": [
    "The lower bound and upper bounds of the metrics were calculated by bootstrapping a 95% confidence interval. Bootstrap methods, in general, consist of estimating a characteristic of the unknown population by simulating the characteristic when the true population is replaced by an esitmated one [see @diciccio1988review]. The 95th percentile method was used to calculate a set of approximate confidence limits for the metrics defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39557a-9960-44f1-91d9-f09c68f8789d",
   "metadata": {},
   "source": [
    "The metric results for the full dataset provided some insights on the limitations of the trained model. A noteworthy limitation is the specificity equal to 0.4 and the sensitificy equal to 0.8. The relatively high sensitivity paired with a low specificity shows that this model overpredics mask wearing. Additional sub-groups were analyzed to see if the model performed better in different scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94913d44-189b-44dc-9b91-b6e668ef6c0b",
   "metadata": {},
   "source": [
    "## DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05a89d-3b1c-4d13-8669-8fc4e901b34e",
   "metadata": {},
   "source": [
    "## RetinaFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e4688-6a14-4693-8dd5-5fc42c4525d0",
   "metadata": {},
   "source": [
    "## Off-the-shelf Mask Inference Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8723d1-ef74-407b-bbb0-fbe307a34697",
   "metadata": {},
   "source": [
    "## Original NN vs Off-the-shelf Mask Inference Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5bab73-ec5a-47ec-bd06-5ccda441e152",
   "metadata": {},
   "source": [
    "# Conclusion - TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec50960-5050-41cc-b594-dfe80fd697ec",
   "metadata": {},
   "source": [
    "* Summary of the main findings and their implications\n",
    "* Limitations of the study and suggestions for future research\n",
    "* Suggestions for future research and improvements to the approach\n",
    "* Discussion of the potential impact of deep learning models on public health policy and compliance monitoring"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "mask-detection",
   "language": "python",
   "name": "mask-detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
